
R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> ######################################################################
> # Author: Begum Topcuoglu
> # Date: 2018-12-20
> # Title: Main pipeline for 7 classifiers in R programming language
> ######################################################################
> 
> ######################################################################
> # Description: 
> 
> # This script will read in data from Baxter et al. 2016
> #     - 0.03 subsampled OTU dataset
> #     - CRC metadata: SRN information
> 
> 
> # It will run the following machine learning pipelines:
> #     - L2 Logistic Regression 
> #     - L1 and L2 Linear SVM
> #     - RBF SVM
> #     - Decision Tree
> #     - Random Forest 
> #     - XGBoost 
> ######################################################################
> 
> ######################################################################
> # Dependencies and Outputs: 
> 
> # Be in the project directory.
> 
> # The outputs are:
> #   (1) AUC values for cross-validation and testing for each data-split 
> #   (2) meanAUC values for each hyper-parameter tested during each split.
> ######################################################################
> 
> 
> ################### IMPORT LIBRARIES and FUNCTIONS ###################
> # The dependinces for this script are consolidated in the first part
> deps = c("reshape2", "kernlab","LiblineaR", "doParallel","pROC", "caret", "gtools", "tidyverse");
> for (dep in deps){
+   if (dep %in% installed.packages()[,"Package"] == FALSE){
+     install.packages(as.character(dep), quiet=TRUE, repos = "http://cran.us.r-project.org");
+   }
+   library(dep, verbose=FALSE, character.only=TRUE)
+ }
Loading required package: foreach
Loading required package: iterators
Loading required package: parallel
Type 'citation("pROC")' for a citation.

Attaching package: ‘pROC’

The following objects are masked from ‘package:stats’:

    cov, smooth, var

Loading required package: lattice
Loading required package: ggplot2

Attaching package: ‘ggplot2’

The following object is masked from ‘package:kernlab’:

    alpha

── Attaching packages ─────────────────────────────────────── tidyverse 1.2.1 ──
✔ tibble  1.4.2     ✔ purrr   0.2.5
✔ tidyr   0.8.1     ✔ dplyr   0.7.6
✔ readr   1.1.1     ✔ stringr 1.3.1
✔ tibble  1.4.2     ✔ forcats 0.3.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ purrr::accumulate() masks foreach::accumulate()
✖ ggplot2::alpha()    masks kernlab::alpha()
✖ purrr::cross()      masks kernlab::cross()
✖ dplyr::filter()     masks stats::filter()
✖ dplyr::lag()        masks stats::lag()
✖ purrr::lift()       masks caret::lift()
✖ purrr::when()       masks foreach::when()
> 
> # Load in needed functions and libraries
> source('code/learning/functions.R')
> source('code/learning/model_selection.R')
> source('code/learning/model_pipeline.R')
> source('code/learning/generateAUCs.R')
Loading required package: magrittr

Attaching package: ‘magrittr’

The following object is masked from ‘package:purrr’:

    set_names

The following object is masked from ‘package:tidyr’:

    extract

Loading required package: permute

Attaching package: ‘permute’

The following object is masked from ‘package:gtools’:

    permute

The following object is masked from ‘package:kernlab’:

    how

This is vegan 2.5-2

Attaching package: ‘vegan’

The following object is masked from ‘package:caret’:

    tolerance

> ######################################################################
> 
> ######################## DATA PREPARATION #############################
> # Features: Hemoglobin levels and 16S rRNA gene sequences in the stool 
> # Labels: - Colorectal lesions of 490 patients. 
> #         - Defined as cancer or not.(Cancer here means: SRN)
> # Read in metadata and select only sample Id and diagnosis columns
> meta <- read.delim('data/metadata.tsv', header=T, sep='\t') %>%
+   select(sample, Dx_Bin, fit_result)
> # Read in OTU table and remove label and numOtus columns
> shared <- read.delim('data/baxter.0.03.subsample.shared', header=T, sep='\t') %>%
+   select(-label, -numOtus)
> # Merge metadata and OTU table.
> # Group advanced adenomas and cancers together as cancer and normal, high risk normal and non-advanced adenomas as normal
> # Then remove the sample ID column
> data <- inner_join(meta, shared, by=c("sample"="Group")) %>%
+   mutate(dx = case_when(
+     Dx_Bin== "Adenoma" ~ "normal",
+     Dx_Bin== "Normal" ~ "normal",
+     Dx_Bin== "High Risk Normal" ~ "normal",
+     Dx_Bin== "adv Adenoma" ~ "cancer",
+     Dx_Bin== "Cancer" ~ "cancer"
+   )) %>%
+   select(-sample, -Dx_Bin) %>%
+   drop_na()
> # We want the diagnosis column to a factor
> data$dx <- factor(data$dx, labels=c("normal", "cancer"))
> ###################################################################
> 
> ######################## RUN PIPELINE #############################
> # Choose which classification methods we want to run
> model_names = c("L2_Logistic_Regression", 
+                 "L2_Linear_SVM", 
+                 "RBF_SVM", 
+                 "Decision_Tree", 
+                 "Random_Forest",
+                 "XGBoost")
> # Get the cv and test AUCs for 100 data-splits
> start_time <- Sys.time()
> model <- as.character(commandArgs(TRUE)) # recieve input from model
> get_AUCs(model)
> end_time <- Sys.time()
> print(end_time - start_time)
Time difference of 0.009172916 secs
> ###################################################################
> 
> 
> 
> 
> 
> proc.time()
   user  system elapsed 
  6.912   0.339   7.370 
