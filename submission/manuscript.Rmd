---
title: "**NAME OF THIS STUDY**"
bibliography: references.bib
output:
  pdf_document:
    keep_tex: true
    includes:
      in_header: header.tex
csl: mbio.csl #Get themes at https://github.com/citation-style-language/styles
fontsize: 11pt
geometry: margin=1.0in
---


```{r knitr_settings, eval=TRUE, echo=FALSE, cache=FALSE,  warning=FALSE, message=FALSE}
# Load useful functions
source('../code/learning/functions.R')
# Read in necessary libraries
deps = c("doParallel","pROC", "caret","knitr","rmarkdown","vegan","gtools", "tidyverse");
for (dep in deps){
  if (dep %in% installed.packages()[,"Package"] == FALSE){
    install.packages(as.character(dep), quiet=TRUE);
  }
  library(dep, verbose=FALSE, character.only=TRUE)
}
opts_chunk$set("tidy" = TRUE)
opts_chunk$set("echo" = FALSE)
opts_chunk$set("eval" = TRUE)
opts_chunk$set("warning" = FALSE)
opts_chunk$set("cache" = FALSE)

inline_hook <- function(x){
	print(x)

	if(is.list(x)){
		x <- unlist(x)
	}

	if(is.numeric(x)){
		if(abs(x - round(x)) < .Machine$double.eps^0.5){
			paste(format(x,big.mark=',', digits=0, scientific=FALSE))
		} else {
			paste(format(x,big.mark=',', digits=1, nsmall=1, scientific=FALSE))
		}
	} else {
    	paste(x)      
	}
}
knitr::knit_hooks$set(inline=inline_hook)
```

```{r LoadData, eval=TRUE, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE}
# Read in metadata and select only sample Id and diagnosis columns
meta <- read.delim('../data/metadata.tsv', header=T, sep='\t') %>%
  select(sample, dx)

# Read in OTU table and remove label and numOtus columns
shared <- read.delim('../data/baxter.0.03.subsample.shared', header=T, sep='\t') %>%
   select(-label, -numOtus)

# Read in AUCs table generated from l2 logistic regression model for all samples
  # Carcinomas + Adenomas are 1 and Normal is 0 for binary predictive model
  # FIT is a feature
  # The scaler is MinMax scaler
logit <- read.delim('../data/process/L2_Logistic_Regression.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="L2-Logistic Regression")

# Read in AUCs table generated from l1 SVM linear kernel for all samples
  # Carcinomas + Adenomas are 1 and Normal is 0 for binary predictive model
  # FIT is a feature
  # The scaler is StandardScaler
l1svm <- read.delim('../data/process/L1_SVM_Linear_Kernel.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="L1-SVM Linear") 

# Read in AUCs table generated from l2 SVM linear kernel for all samples
  # Carcinomas + Adenomas are 1 and Normal is 0 for binary predictive model
  # FIT is a feature
  # The scaler is StandardScaler
l2svm <- read.delim('../data/process/L2_SVM_Linear_Kernel.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="L2-SVM Linear")

# Read in AUCs table generated from  SVM RBF kernel for all samples
  # Carcinomas + Adenomas are 1 and Normal is 0 for binary predictive model
  # FIT is a feature
  # The scaler is StandardScaler
svmRBF <- read.delim('../data/process/SVM_RBF.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="SVM RBF")

# Read in AUCs table generated from xgboost for all samples
  # Carcinomas + Adenomas are 1 and Normal is 0 for binary predictive model
  # FIT is a feature
  # The scaler is MinMaxScaler
xgboost <- read.delim('../data/process/XGBoost.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="XGBoost")

# Read in AUCs table generated from random forest for all samples
  # Carcinomas + Adenomas are 1 and Normal is 0 for binary predictive model
  # FIT is a feature
  # The scaler is MinMaxScaler
rf <- read.delim('../data/process/Random_Forest.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="Random Forest ")

# Read in AUCs table generated from decision tree for all samples
  # Carcinomas + Adenomas are 1 and Normal is 0 for binary predictive model
  # FIT is a feature
  # The scaler is MinMaxScaler
dt <- read.delim('../data/process/Decision_Tree.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="Decision Tree")

# Put  all the AUCs for all the models together and group by model
all <- bind_rows(logit, l1svm, l2svm, svmRBF, xgboost, rf, dt) %>% 
  group_by(model)
```

```{r model_parameters, echo=FALSE, results='asis'}
model_param <- read.table('../data/process/model_parameters.txt', header=T, sep='\t')
kable(model_param, caption = "Table 1 Parameters and software implementation of the classification algorithms")
```
\vspace{35mm}

Running title: INSERT RUNNING TITLE HERE

\vspace{35mm}


Begüm D. Topçuoğlu^1, Jenna Wiens^2, Patrick D. Schloss^1$\dagger$^

\vspace{40mm}

$\dagger$ To whom correspondence should be addressed: pschloss@umich.edu

1\. Department of Microbiology and Immunology, University of Michigan, Ann Arbor, MI 48109

2\. Department of Computer Science and Engineering, University or Michigan, Ann Arbor, MI 49109


\newpage
\linenumbers


## Abstract


\newpage

## Introduction

As gut microbiome field continues to grow, there will be an ever-increasing demand for reproducible machine learning  methods to analyze microbiome sequence read count data and to determine association with a continuous or categorical phenotype of interest.

Colorectal cancer is one of the leading cause of death among cancers in the United States. Early diagnosis increases the chance of survival. However the current diagnostic methods are expensive and invasive. As a less invasive tool, numerous studies use relative abundances of the gut bacteria populations to predict disease progression. Most microbial communities are pretty patchy and the likelihood of a single feature that explains the differences in health is pretty small. It is likely that many biomarkers are needed to account for the patchiness as well as the context dependency of the features.


ML use in microbiome literature is a bit like the wild west with lack of clarity over methods, testing, validation, etc. There is a need for guidance on how to properly implement these different methods. We need to emphasize good machine learning practices and pipelines and discuss the reproducibility, robustness and actionability of models. 


We established a non-leaky pipeline. We performed L1 and L2-regularized logistic regression, Linear SVM, Non-Linear SVM, Decision tree, Random forest, XGBoost and Feed Forward Neural Net classification models. We evaluated the classification performance of different machine learning methods. We also want to discuss the reproducibility, robustness, actionability, interpretibility and susceptibility to overfitting of each method. 

Generalisation Perfomance of each model. 
Is there a maximum threshold of prediction with all these methods?
Does an increase in model complexity improve predictibility?
Synthesis statement regarding modeling 16S microbiome data

## Results and Discussion


## Conclusions


## Materials and Methods


\newpage

Insert figure legends with the first sentence in bold, for example:

**Figure 1. Number of OTUs sampled among bacterial and archaeal 16S rRNA gene sequences for different OTU definitions and level of sequencing effort.** Rarefaction curves for different OTU definitions of Bacteria (A) and Archaea (B). Rarefaction curves for the coarse environments in Table 1 for Bacteria (C) and Archaea (D).


\newpage

## References
