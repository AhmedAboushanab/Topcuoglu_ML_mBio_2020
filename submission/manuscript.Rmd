---
title: "**Evaluation of binary classification pipelines and methods for 16S rRNA gene data**"
bibliography: references.bib
output:
  word_document: default
  pdf_document:
    keep_tex: true
    includes:
      in_header: header.tex
csl: mbio.csl #Get themes at https://github.com/citation-style-language/styles
fontsize: 11pt
geometry: margin=1.0in
---


```{r knitr_settings, eval=TRUE, echo=FALSE, cache=FALSE,  warning=FALSE, message=FALSE}
######################################################################
#----------------- Read in necessary libraries -------------------#
######################################################################
deps = c("knitr","rmarkdown","vegan","gtools", "tidyverse");
for (dep in deps){
  if (dep %in% installed.packages()[,"Package"] == FALSE){
    install.packages(as.character(dep), quiet=TRUE);
  }
  library(dep, verbose=FALSE, character.only=TRUE)
}
######################################################################
#-------------- Define the chunk options ----------------#
######################################################################
opts_chunk$set("tidy" = TRUE)
opts_chunk$set("echo" = FALSE)
opts_chunk$set("eval" = TRUE)
opts_chunk$set("warning" = FALSE)
opts_chunk$set("cache" = FALSE)

inline_hook <- function(x){
	print(x)

	if(is.list(x)){
		x <- unlist(x)
	}

	if(is.numeric(x)){
		if(abs(x - round(x)) < .Machine$double.eps^0.5){
			paste(format(x,big.mark=',', digits=0, scientific=FALSE))
		} else {
			paste(format(x,big.mark=',', digits=1, nsmall=1, scientific=FALSE))
		}
	} else {
    	paste(x)      
	}
}
knitr::knit_hooks$set(inline=inline_hook)
library(reticulate)
use_python("/Library/Frameworks/Python.framework/Versions/3.6/bin/python3", required = TRUE)
```

```{r LoadData, eval=TRUE, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE}
######################################################################
#----------------- Load OTU table and MetaData -----------------#
######################################################################

# Read in metadata and select only sample Id and diagnosis columns
meta <- read.delim('../data/metadata.tsv', header=T, sep='\t') %>%
  select(sample, dx, Dx_Bin, fit_result)


# Read in OTU table and remove label and numOtus columns
shared <- read.delim('../data/baxter.0.03.subsample.shared', header=T, sep='\t') %>%
   select(-label, -numOtus)

######################################################################
#---Load .tsv data with CV and test AUC data generated in Python ----#
######################################################################

# Read in AUCs table generated from L2 logistic regression model for all samples:
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is MinMax scaler
logit <- read.delim('../data/process/L2_Logistic_Regression.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="L2-Logistic Regression")

logit_summary <- logit %>%  
  group_by(Performance) %>% 
  summarise(meanAUC=mean(AUC), std=sd(AUC)) 

cv_meanAUC <- logit_summary[1,2]
cv_sdAUC <- logit_summary[1,3]
test_meanAUC <- logit_summary[2,2]
test_sdAUC <- logit_summary[2,3]

# Read in AUCs table generated from l1 SVM linear kernel for all samples
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is Standard scaler
l1svm <- read.delim('../data/process/L1_SVM_Linear_Kernel.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="L1-SVM Linear") 

l1svm_summary <- l1svm %>%  
  group_by(Performance) %>% 
  summarise(meanAUC=mean(AUC), std=sd(AUC))

# Read in AUCs table generated from l2 SVM linear kernel for all samples
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is Standard scaler
l2svm <- read.delim('../data/process/L2_SVM_Linear_Kernel.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="L2-SVM Linear")

l2svm_summary <- l2svm %>%  
  group_by(Performance) %>% 
  summarise(meanAUC=mean(AUC), std=sd(AUC))

# Read in AUCs table generated from  SVM RBF kernel for all samples
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is Standard scaler
svmRBF <- read.delim('../data/process/SVM_RBF.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="SVM RBF")

svmRBF_summary <- svmRBF %>%  
  group_by(Performance) %>% 
  summarise(meanAUC=mean(AUC), std=sd(AUC))

# Read in AUCs table generated from xgboost for all samples
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is MinMax (0-1) scaler
xgboost <- read.delim('../data/process/XGBoost.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="XGBoost")

xgboost_summary <- xgboost %>%  
  group_by(Performance) %>% 
  summarise(meanAUC=mean(AUC), std=sd(AUC))

# Read in AUCs table generated from random forest for all samples
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is MinMax (0-1) scaler
rf <- read.delim('../data/process/Random_Forest.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="Random Forest ")

rf_summary <- rf %>%  
  group_by(Performance) %>% 
  summarise(meanAUC=mean(AUC), std=sd(AUC))
# Read in AUCs table generated from decision tree for all samples
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is MinMax (0-1) scaler
dt <- read.delim('../data/process/Decision_Tree.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="Decision Tree")

dt_summary <- dt %>%  
  group_by(Performance) %>% 
  summarise(meanAUC=mean(AUC), std=sd(AUC))
```

```{python, cache=FALSE, message=FALSE, warning=FALSE, engine.path = '/Library/Frameworks/Python.framework/Versions/3.6/bin/python3'}
import platform
python_version = platform.python_version()
import sklearn
sklearn_module = sklearn.__version__
```

\vspace{35mm}

Running title: Machine learning methods in microbiome studies

\vspace{35mm}


Begüm D. Topçuoğlu${^1}$, Jenna Wiens${^2}$, Patrick D. Schloss^1$\dagger$^

\vspace{40mm}

$\dagger$ To whom correspondence should be addressed: pschloss@umich.edu

1\. Department of Microbiology and Immunology, University of Michigan, Ann Arbor, MI 48109

2\. Department of Computer Science and Engineering, University or Michigan, Ann Arbor, MI 49109


\newpage
\linenumbers


## Abstract

As the microbiome field continues to grow, there is an ever-increasing demand for reproducible machine learning methods for identifying associations between members of the microbiome and phenotypes. Currently, the field’s use of machine learning lacks clarity and consistency. There is a need to implement good machine learning practices to generate reproducible and robust models. One application of machine learning to microbiome data has been to classify patients as having colorectal tumors based on microbiota-associated biomarkers. Colorectal cancer is one of the leading cause of death among cancers in the United States. Colonoscopy as a screening tool is effective, however it is invasive and have a low rate of patient adherence. Previous studies have shown that bacterial abundances in the stool can predict colorectal tumors in the colon and can be used as a non-invasive screening tool.  However, the prediction performance of these models vary greatly, with areas under the receiver operating characteristic curve (AUC) of 0.7-0.9 [@sze_leveraging_2018; @baxter_microbiota-based_2016; @baxter_dna_2016; @zackular_human_2014]. We used the fecal hemoglobin concentration and 16S rRNA gene sequences from stool samples to classify `r paste(nrow(meta))` patients as having advanced tumors or not. Modeling pipelines were established for L2-regularized Logistic Regression, L1 and L2 Linear Support Vector Machines (SVM), Radial Basis Function SVM, Decision Tree, Random Forest and Extreme Gradient Boosting (XGBoost) binary classification models. Tree-based methods, namely Decision Tree, Random Forest and XGBoost were less susceptible to overfitting and in general had higher sensitivity and specificity for advanced tumors. Aside from evaluating generalization and classification performance of each model, this study established standards for modeling pipelines of microbiome-associated machine learning models.   

\newpage

## Introduction


Colorectal cancer is the second most commonly occurring cancer in men and third in women, with 1.8 million new cases in 2018 (8). Early detection of screen-relevant neoplasias (SRN) which are cancerous or advanced precancerous lesions, is crucial for treatment of colorectal cancer. Patients whose lesions are detected at an early stage have a greater than 90 % chance of survival, yet a significant proportion of the US population remain unscreened (9). The high cost and invasiveness of screening methods such as colonoscopy and sigmoidoscopy lower patient adherence. There is a need for non-invasive screening tests that have high sensitivity and specificity for SRN. 

Patients with colorectal cancer have different stool community of microbes than adults with normal colons (10–15). This difference however cannot be explained by a single species in the gut but by many of them in relation to one another. Therefore, machine learning emerged as a tool to identify the microbial biomarkers of CRC. Previous studies that used cohorts of 90 (30 SRN, 30 adenomas, 30 normal colons) (7) and 490 (229 SRN, 89 adenoma, 172 normal colons) patients (5) suggest that machine learning models can predict SRN. However, the prediction performance of previous models varies greatly. There is a need for implementing consistent and transparent machine learning practices to generate reproducible and replicable CRC biomarker models. This study aims to determine whether a reproducible and replicable classification model that incorporate the relative abundance of fecal bacterial populations can be developed to discriminate between individuals with and without, SRN.

Here, colonic disease status is defined as Normal or Screen Relevant Neoplasias (SRN). Stool bacterial population abundances and stool hemoglobin levels of `r paste(sum(sum(meta$dx=="normal")+sum(meta$Dx_Bin=="Adenoma")))` Normal and `r paste(sum(sum(meta$dx=="cancer")+sum(meta$Dx_Bin=="adv Adenoma")))` SRN samples were used to learn binary classifiers and evaluate their performances. Modeling pipelines were established for L2-regularized Logistic Regression, L1 and L2 Linear Support Vector Machines (SVM), Radial Basis Function SVM, Decision Tree, Random Forest and XGBoost binary classification models. The mean AUCs of these models were `r paste(round(test_meanAUC,2))` ± `r paste(round(test_sdAUC,2))`,  `r paste(round(l1svm_summary[2,2],2))` ± `r paste(round(l1svm_summary[2,3],2))`,  `r paste(round(l2svm_summary[2,2],2))` ± `r paste(round(l2svm_summary[2,3],2))`, `r paste(round(svmRBF_summary[2,2],2))` ± `r paste(round(svmRBF_summary[2,3],2))`, `r paste(round(dt_summary[2,2],2))` ± `r paste(round(dt_summary[2,3],2))`, `r paste(round(rf_summary[2,2],2))` ± `r paste(round(rf_summary[2,3],2))`, and `r paste(round(xgboost_summary[2,2],2))` ± `r paste(round(xgboost_summary[2,3],2))`, respectively.

## Results and Discussion

##### Results of modeling in text, tables and figures

##### Comparisons among modeling approaches

#### Interpretation of modeling results in terms of reproducibility, robustness, actionability, interpretibility and susceptibility

#### Consideration of possible weaknesses for each model 

The interactions between the biomarkers may be nonlinear. Obviously, the linear models will not incorporate this because they are linear. Tools like linear models (e.g. metastats, lefse, wilcoxon, etc) are likely worthless.

#### Consideration of possible weaknesses for our approach and chosen dataset

#### Relationship of results to previous literature and broader implications of this work

#### Prospects of future progress

## Conclusions



## Materials and Methods

#### Data collection
  The data used for this analysis are stool bacterial abundances, stool hemoglobin levels and clinical information of the patients recruited by Great Lakes-New England Early Detection Research Network study. These data were obtained from Sze et al [@sze_leveraging_2018]. 
  The stool samples were provided by recruited adult participants who were undergoing scheduled screening or surveillance colonoscopy. Colonoscopies were performed and fecal samples were collected from participants in four locations: Toronto (ON, Canada), Boston (MA, USA), Houston (TX, USA), and Ann Arbor (MI, USA). Patients' colonic disease status was defined by colonoscopy with adequate preparation and tissue histopathology of all resected lesions. Patients with an adenoma greater than 1 cm, more than three adenomas of any size, or an adenoma with villous histology were classified as advanced adenoma. Study had `r paste(sum(meta$dx=="normal"))` patients with normal colonoscopies, `r paste(sum(meta$dx=="adenoma"))` with adenomas and `r paste(sum(meta$dx=="cancer"))` with carcinomas. Of the `r paste(sum(meta$dx=="adenoma"))` adenomas, `r paste(sum(meta$Dx_Bin=="adv Adenoma"))` were identified as advanced adenomas. Stool provided by the patients was used for Fecal Immunological Tests (FIT) which measure human hemoglobin concentrations and for 16S rRNA gene sequencing to measure bacterial population abundances. The bacterial abundance data was generated by Sze et al, by processing 16S rRNA sequences in Mothur (v1.39.3) using the default quality filtering methods, identifying and removing chimeric sequences using VSEARCH and assigning to OTUs at 97% similarity using the OptiClust algorithm [@schloss_introducing_2009; @westcott_opticlust_2017; @rognes_vsearch_2016].

#### Data definitions and pre-processing

  The colonic disease status is re-defined as two encompassing classes; Normal or Screen Relevant Neoplasias (SRNs). Normal class includes patients with non-advanced adenomas or normal colons whereas SRN class includes patients with advanced adenomas or carcinomas. Colonic disease status is the label predicted with each classifier.   The bacterial abundances and FIT results are the features used to predict colonic disease status. Bacterial abundances are discrete data in the form of Operational Taxonomic Unit (OTU) counts. There are 6920 OTUs for each sample. FIT levels are continuous data present for each sample. Because the data are in different scales, Python programming language v`r paste(py$python_version)`, module scikit-learn v`r paste(py$sklearn_module)` is used to transform features by scaling each feature to a [0-1] range (Table 1) [@scikit-learn].
  
#### Learning the Classifier

  To train and validate our model, labeled data is randomly split 80/20 into a training set and testing
set. Then, seven binary class classifiers, L2 logistic regression, L1 and L2 linear suppor vector machines (SVM), radial basis function SVM, decision tree, random forest and XGBoost, are learned. The training set is used for training purposes and validation of hyperparameter selection, and the test set is used for evaluation purposes. Hyperparameters are selected using 5-fold cross-validation with 100-repeats on the training set. Since the colonic disease status are not uniformly represented in the data, 5-fold splits are stratified to maintain the overall label distribution on the training set. Python programming language v`r paste(py$python_version)`, module scikit-learn v`r paste(py$sklearn_module)` functions are used to learn the seven classifiers (Table 1). 

#### Classifier Performance

  The classification performance of learned classifier is evaluated on the labeled held-out testing set. The optimal  classifier with optimal hyperparameters selected in the cross-validation step is used to produce a prediction for the testing set. The performance of this prediction is measured in terms of the sensitivity and specificity, in addition to Area Under the Curve (AUC) metrics. This process of splitting the data, learning a classifier with cross-validation, and testing the classifier is repeated on 100 different splits. In the end cross-validation AUC and testing AUC averaged over the 100 different training/test splits are reported. Hyperparameter budget and performance for each split is also reported. 


\newpage



**Figure 1. Generalization and classification performance of modeling methods ** AUC values of all cross validation and testing performances. The boxplot shows quartiles at the box ends and the statistical median as the horizontal line in the box. The whiskers show the farthest points that are not outliers. Outliers are data points that are not within 3/2 times the interquartile ranges. 

\newpage

## References

<div id="refs"></div>


