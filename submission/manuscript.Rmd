---
title: "**Evalution of binary classification pipelines and methods for 16S rRNA gene data**"
bibliography: references.bib
output:
  pdf_document:
    keep_tex: true
    includes:
      in_header: header.tex
csl: mbio.csl #Get themes at https://github.com/citation-style-language/styles
fontsize: 11pt
geometry: margin=1.0in
---


```{r knitr_settings, eval=TRUE, echo=FALSE, cache=FALSE,  warning=FALSE, message=FALSE}
######################################################################
#----------------- Read in necessary libraries -------------------#
######################################################################
deps = c("doParallel","pROC", "caret","knitr","rmarkdown","vegan","gtools", "tidyverse");
for (dep in deps){
  if (dep %in% installed.packages()[,"Package"] == FALSE){
    install.packages(as.character(dep), quiet=TRUE);
  }
  library(dep, verbose=FALSE, character.only=TRUE)
}
######################################################################
#-------------- Define the chunk options ----------------#
######################################################################
opts_chunk$set("tidy" = TRUE)
opts_chunk$set("echo" = FALSE)
opts_chunk$set("eval" = TRUE)
opts_chunk$set("warning" = FALSE)
opts_chunk$set("cache" = FALSE)

inline_hook <- function(x){
	print(x)

	if(is.list(x)){
		x <- unlist(x)
	}

	if(is.numeric(x)){
		if(abs(x - round(x)) < .Machine$double.eps^0.5){
			paste(format(x,big.mark=',', digits=0, scientific=FALSE))
		} else {
			paste(format(x,big.mark=',', digits=1, nsmall=1, scientific=FALSE))
		}
	} else {
    	paste(x)      
	}
}
######################################################################
#-------------- Define knitr options to allow kable ----------------#
######################################################################
knitr::knit_hooks$set(inline=inline_hook)
options(kableExtra.latex.load_packages = FALSE)
options(kableExtra.auto_format = FALSE)
options(knitr.table.format = "latex")
library(kableExtra)
```

```{r LoadData, eval=TRUE, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE}
######################################################################
#----------------- Load OTU table and MetaData -----------------#
######################################################################

# Read in metadata and select only sample Id and diagnosis columns
meta <- read.delim('../data/metadata.tsv', header=T, sep='\t') %>%
  select(sample, dx)

# Read in OTU table and remove label and numOtus columns
shared <- read.delim('../data/baxter.0.03.subsample.shared', header=T, sep='\t') %>%
   select(-label, -numOtus)

######################################################################
#------------ Load .tsv data generated in Python -----------------#
######################################################################

# Read in AUCs table generated from L2 logistic regression model for all samples:
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is MinMax scaler
logit <- read.delim('../data/process/L2_Logistic_Regression.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="L2-Logistic Regression")

# Read in AUCs table generated from l1 SVM linear kernel for all samples
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is Standard scaler
l1svm <- read.delim('../data/process/L1_SVM_Linear_Kernel.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="L1-SVM Linear") 

# Read in AUCs table generated from l2 SVM linear kernel for all samples
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is Standard scaler
l2svm <- read.delim('../data/process/L2_SVM_Linear_Kernel.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="L2-SVM Linear")

# Read in AUCs table generated from  SVM RBF kernel for all samples
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is Standard scaler
svmRBF <- read.delim('../data/process/SVM_RBF.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="SVM RBF")

# Read in AUCs table generated from xgboost for all samples
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is MinMax (0-1) scaler
xgboost <- read.delim('../data/process/XGBoost.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="XGBoost")

# Read in AUCs table generated from random forest for all samples
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is MinMax (0-1) scaler
rf <- read.delim('../data/process/Random_Forest.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="Random Forest ")

# Read in AUCs table generated from decision tree for all samples
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is MinMax (0-1) scaler
dt <- read.delim('../data/process/Decision_Tree.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="Decision Tree")

######################################################################
#------------ Put all the loaded AUC tables together -----------------#
######################################################################
all <- bind_rows(logit, l1svm, l2svm, svmRBF, xgboost, rf, dt) %>% 
  group_by(model)
```

```{r table_1_models, echo=FALSE, results='asis'}
######################################################################
# We load a model parameters file to make our Table 1. Model parameters file has the information of optimized hyper-parameters, pre-processing and cross-validation methods and software implementation for all the classification algorithms.

# This file is hand-made. Therefore needs to be changed manually if new information wants to be added or information needs to be changed. 
######################################################################
model_param <- read.table('../data/process/model_parameters.txt', header=T, sep='\t') %>% 
   select(Method, Parameter, Cross.Validation, Epochs, Scaler, Sklearn.Function) %>% 
  rename("Cross Validation"="Cross.Validation") %>%
  rename("Epoch"="Epochs") %>%
  rename("Sklearn Function"="Sklearn.Function")

#------------------------Table 1 generation------------------------#

Table1 <- kable(model_param, 
                "latex", 
                caption = "Optimized hyper-parameters, pre-processing and cross-validation methods and software implementation of the classification algorithms.", 
                booktabs = T, 
                linesep = "") %>%
kable_styling(latex_options = c("striped", "scale_down"), 
              position = "left") %>%  
 column_spec(1, width="10em") %>%
  column_spec(2, width="8em") %>% 
  column_spec(3, width="9em") %>%
  column_spec(5, width="5em") %>% 
  row_spec(1:7, align="l") %>% 
  row_spec(0,bold=TRUE)
```

```{r table_2_3_params, echo=FALSE, results='asis'}
######################################################################
# We load a param_grid.scv file to make our Table 2 and 3. This file has the information of the ranges of the optimized hyper-parameters for each model.

# This file is generated from model_selection.py that is used to define model parameters for main.py. Therefore any changes to those files would allow us to represent them in the tables automatically.  

# 1) First we will generate a Table for non-tree based models that shows C(penalty) and gamma hyperparameters.

# 2) Second we will generate a Table for tree based models that show all the hyperparameters used for it. 
######################################################################


################ Non-tree based model parameters ##############
linear_param_range <- read.table('../data/process/param_grid.csv', header=T, sep=',', na.strings="", stringsAsFactors = FALSE) %>% 
  replace(is.na(.), "-")  %>% 
  ## only select Logistic Regression and SVM model columns
  select(1:17) %>% 
  ## only select C (penalty) and gamma rows as parameters
   slice(1:2) 

#------------------------Table 2 generation------------------------#
Table2 <- kable(linear_param_range, 
                "latex", 
                caption = "The range of optimized hyper-parameters for logistic regression and support vector machines.", 
                booktabs = T, 
                col.names = NULL, 
                linesep = "") %>%
  # latex options make table to be condensed
  # table itseld if left aligned
  kable_styling(latex_options = c("striped", "scale_down"), 
                position = "left") %>% 
  # the column names are removed when the file is read so I put headers above the grouped/replicated modeling method for
  add_header_above(c("Parameter", "L2 Logistic" = 4, "L1 SVM Linear" = 4, "L2 SVM Linear " = 3, "SVM RBF"=5), bold=TRUE) %>% 
  # Put a left border to seperate above header lines
  column_spec(2, border_left = T) %>%
  column_spec(6, border_left = T) %>% 
  column_spec(10, border_left = T) %>% 
  column_spec(13, border_left = T)

################ Tree based model parameters ##############
tree_param_range <- read.table('../data/process/param_grid.csv', header=T, sep=',', na.strings="", stringsAsFactors = FALSE) %>% 
  replace(is.na(.), "-")  %>% 
  ## only select Logistic Regression and SVM model columns
  select(1, 18:29) %>% 
  ## select all rows except C (penalty) and gamma for parameters
  slice(3:9)

#------------------------Table 3 generation------------------------#
Table3 <- kable(tree_param_range, 
                "latex", 
                caption = "The range of optimized hyper-parameters for tree based classification algorithms.", 
                booktabs = T, 
                col.names = NULL, 
                linesep = "") %>%
kable_styling(latex_options = c("striped", "scale_down"), 
              position = "left", font_size=6) %>% 
  add_header_above(c("Parameter", "Random Forest"=5, "Decision Tree"= 4, "XGBoost"=3 ), bold=TRUE) %>% 
  column_spec(2, border_left = T) %>% 
  column_spec(7, border_left = T)%>% 
  column_spec(11, border_left = T)
```
\vspace{35mm}

Running title: Machine learning methods in microbiome studies

\vspace{35mm}


Begüm D. Topçuoğlu^1, Jenna Wiens^2, Patrick D. Schloss^1$\dagger$^

\vspace{40mm}

$\dagger$ To whom correspondence should be addressed: pschloss@umich.edu

1\. Department of Microbiology and Immunology, University of Michigan, Ann Arbor, MI 48109

2\. Department of Computer Science and Engineering, University or Michigan, Ann Arbor, MI 49109


\newpage
\linenumbers


## Abstract


\newpage

## Introduction

As gut microbiome field continues to grow, there will be an ever-increasing demand for reproducible machine learning  methods to analyze microbiome sequence read count data and to determine association with a continuous or categorical phenotype of interest.

Colorectal cancer is one of the leading cause of death among cancers in the United States. Early diagnosis increases the chance of survival. However the current diagnostic methods are expensive and invasive. As a less invasive tool, numerous studies use relative abundances of the gut bacteria populations to predict disease progression. Most microbial communities are pretty patchy and the likelihood of a single feature that explains the differences in health is pretty small. It is likely that many biomarkers are needed to account for the patchiness as well as the context dependency of the features.


ML use in microbiome literature is a bit like the wild west with lack of clarity over methods, testing, validation, etc. There is a need for guidance on how to properly implement these different methods. We need to emphasize good machine learning practices and pipelines and discuss the reproducibility, robustness and actionability of models. 


We established a non-leaky pipeline. We performed L1 and L2-regularized logistic regression, Linear SVM, Non-Linear SVM, Decision tree, Random forest, XGBoost and Feed Forward Neural Net classification models. We evaluated the classification performance of different machine learning methods. We also want to discuss the reproducibility, robustness, actionability, interpretibility and susceptibility to overfitting of each method. 

Generalisation Perfomance of each model. 
Is there a maximum threshold of prediction with all these methods?
Does an increase in model complexity improve predictibility?
Synthesis statement regarding modeling 16S microbiome data

## Results and Discussion


## Conclusions


## Materials and Methods


\newpage

**Figure 1. Generalization and classification performance of modeling methods ** AUC values of all cross validation and testing performances.
\begin{center}
\includegraphics[width=7in]{../results/figures/AUC_comparison.pdf}
\end{center}

```{r}
Table1
Table2
Table3
```



