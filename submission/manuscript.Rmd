---
title: "**Evaluation of binary classification pipelines and methods for 16S rRNA gene data**"
bibliography: references.bib
output:
  word_document: default
  pdf_document:
    keep_tex: true
    includes:
      in_header: header.tex
csl: mbio.csl #Get themes at https://github.com/citation-style-language/styles
fontsize: 11pt
geometry: margin=1.0in
---


```{r knitr_settings, eval=TRUE, echo=FALSE, cache=FALSE,  warning=FALSE, message=FALSE}
######################################################################
#----------------- Read in necessary libraries -------------------#
######################################################################
deps = c("knitr","rmarkdown","vegan","gtools", "tidyverse");
for (dep in deps){
  if (dep %in% installed.packages()[,"Package"] == FALSE){
    install.packages(as.character(dep), quiet=TRUE);
  }
  library(dep, verbose=FALSE, character.only=TRUE)
}
######################################################################
#-------------- Define the chunk options ----------------#
######################################################################
opts_chunk$set("tidy" = TRUE)
opts_chunk$set("echo" = FALSE)
opts_chunk$set("eval" = TRUE)
opts_chunk$set("warning" = FALSE)
opts_chunk$set("cache" = FALSE)

inline_hook <- function(x){
	print(x)

	if(is.list(x)){
		x <- unlist(x)
	}

	if(is.numeric(x)){
		if(abs(x - round(x)) < .Machine$double.eps^0.5){
			paste(format(x,big.mark=',', digits=0, scientific=FALSE))
		} else {
			paste(format(x,big.mark=',', digits=1, nsmall=1, scientific=FALSE))
		}
	} else {
    	paste(x)      
	}
}
knitr::knit_hooks$set(inline=inline_hook)
library(reticulate)
use_python("/Library/Frameworks/Python.framework/Versions/3.6/bin/python3", required = TRUE)
```

```{r LoadData, eval=TRUE, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE}
######################################################################
#----------------- Load OTU table and MetaData -----------------#
######################################################################

# Read in metadata and select only sample Id and diagnosis columns
meta <- read.delim('../data/metadata.tsv', header=T, sep='\t') %>%
  select(sample, dx, Dx_Bin, fit_result)


# Read in OTU table and remove label and numOtus columns
shared <- read.delim('../data/baxter.0.03.subsample.shared', header=T, sep='\t') %>%
   select(-label, -numOtus)

######################################################################
#---Load .tsv data with CV and test AUC data generated in Python ----#
######################################################################

# Read in AUCs table generated from L2 logistic regression model for all samples:
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is MinMax scaler
logit <- read.delim('../data/process/L2_Logistic_Regression.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="L2-Logistic Regression")

# Read in AUCs table generated from l1 SVM linear kernel for all samples
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is Standard scaler
l1svm <- read.delim('../data/process/L1_SVM_Linear_Kernel.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="L1-SVM Linear") 

# Read in AUCs table generated from l2 SVM linear kernel for all samples
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is Standard scaler
l2svm <- read.delim('../data/process/L2_SVM_Linear_Kernel.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="L2-SVM Linear")

# Read in AUCs table generated from  SVM RBF kernel for all samples
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is Standard scaler
svmRBF <- read.delim('../data/process/SVM_RBF.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="SVM RBF")

# Read in AUCs table generated from xgboost for all samples
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is MinMax (0-1) scaler
xgboost <- read.delim('../data/process/XGBoost.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="XGBoost")

# Read in AUCs table generated from random forest for all samples
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is MinMax (0-1) scaler
rf <- read.delim('../data/process/Random_Forest.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="Random Forest ")

# Read in AUCs table generated from decision tree for all samples
#       Carcinomas + Adenomas are 1 and Normal is 0 for binary.
#       FIT is a feature
#       The scaler is MinMax (0-1) scaler
dt <- read.delim('../data/process/Decision_Tree.tsv', header=T, sep='\t') %>%
  select(level_1, AUC) %>% 
  rename(Performance = level_1) %>% 
  mutate(model="Decision Tree")

######################################################################
#------------ Put all the loaded AUC tables together -----------------#
######################################################################
all <- bind_rows(logit, l1svm, l2svm, svmRBF, xgboost, rf, dt) %>% 
  group_by(model)



######################################################################
#---Load .tsv data with cvAUCs for hyper-parameters  ----#
######################################################################
# Read in hyper-parameter AUCs generated from L2 logistic regression model for all samples:
logit <- read.delim('../data/process/L2_Logistic_Regression_parameters.tsv', header=T, sep='\t')%>%
  select(-X) %>% 
  mutate(meanAUC=rowMeans(.[, 2:101])) %>% 
  select(C, meanAUC) 
# Read in hyper-parameter AUCs generated from L1 Linear SVM model for all samples:
l1svm <- read.delim('../data/process/L1_SVM_Linear_Kernel_parameters.tsv', header=T, sep='\t')%>%
  select(-X) %>% 
  mutate(meanAUC=rowMeans(.[, 2:101])) %>% 
  select(C, meanAUC) 
# Read in hyper-parameter AUCs generated from L2 Linear SVM model for all samples:
l2svm <- read.delim('../data/process/L2_SVM_Linear_Kernel_parameters.tsv', header=T, sep='\t')%>%
  select(-X) %>% 
  mutate(meanAUC=rowMeans(.[, 2:101])) %>% 
  select(C, meanAUC) 

```

```{python, cache=FALSE, message=FALSE, warning=FALSE, engine.path = '/Library/Frameworks/Python.framework/Versions/3.6/bin/python3'}
import platform
python_version = platform.python_version()
import sklearn
sklearn_module = sklearn.__version__
```

\vspace{35mm}

Running title: Machine learning methods in microbiome studies

\vspace{35mm}


Begüm D. Topçuoğlu${^1}$, Jenna Wiens${^2}$, Patrick D. Schloss^1$\dagger$^

\vspace{40mm}

$\dagger$ To whom correspondence should be addressed: pschloss@umich.edu

1\. Department of Microbiology and Immunology, University of Michigan, Ann Arbor, MI 48109

2\. Department of Computer Science and Engineering, University or Michigan, Ann Arbor, MI 49109


\newpage
\linenumbers


## Abstract


\newpage

## Introduction

As gut microbiome field continues to grow, there will be an ever-increasing demand for reproducible machine learning  methods to analyze 16S rRNA gene sequence data and to determine association of the microbiome with a continuous or categorical phenotype of interest. The use of machine learning in microbiome literature lack clarity over the learning pipeline which spans the problem formulation, feature selection, feature pre-processing, model learning, and output. There is a need for guidance on how to properly implement good machine learning practices to generate reproducible, robust and actionable models. There is also a clinical need to generate interpretable models for biomedical researchers and clinicans to adopt and use regularly [@wiens_editorial:_2016]. 

Recently, there is an interest on using machine learning to predict colorectal cancer progression with microbiota-assiciated biomarkers. Colorectal cancer is one of the leading cause of death among cancers in the United States. Each person in the industrialized world has on average a one-in-twenty chance of developing colorectal cancer (CRC) in their lifetime and once diagnosed, more than one-third will not survive 5 years [@seer_2016; @street_colorectal_nodate; @weir_past_2015]. Colonoscopy as a screening tool is very effective, however it is very invasive, expensive and have a low rate of patient adherence. Therefore, there is a need for improved non-invasive methods to screen individuals. Gut microbiome-based biomarkers can be used as a non-invasive screening method. 

Patients with colorectal cancer have different stool community of microbes compared to adults with normal colons. This difference however cannot be explained by a single or a handful of candidate taxa in the gut microbiome but by many of them in relation to one another. Therefore, machine learning emerges as a tool to detect the difference between the gut microbiomes of CRC patients and healthy individuals. Previous studies have shown that human hemoglobin levels and bacterial population abundances in the stool help us predict screen relevant growth in the colon, however the literature for the problem of classifying colorectal disease status vary greatly, with areas under the receiver operating characteristic curve (AUC) of 0.7-0.9 [@sze_leveraging_2018; @baxter_microbiota-based_2016; @baxter_dna_2016; @zackular_human_2014]. The variation in classification performance is based in part on differences in the task definition, in part on differences in the study populations, and in part on the learning pipeline. In this study, classification pipelines with L2-regularized logistic regression, L1 and L2 linear suppor vector machines (SVM), radial basis function SVM , decision tree, random forest and XGBoost classifiers are established. The generalization and prediction performance of these classifiers are evaluated and each classifier is examined for its reproducibility, robustness, actionability, interpretibility and susceptibility to overfitting.

Here, colonic disease status is defined as Normal or Screen Relevant Neoplasias (SRN). Stool bacterial population abundances and stool hemoglobin levels of `r paste(sum(sum(meta$dx=="normal")+sum(meta$Dx_Bin=="Adenoma")))` Normal and `r paste(sum(sum(meta$dx=="cancer")+sum(meta$Dx_Bin=="adv Adenoma")))` SRN samples were used to learn binary classifiers and evaluate their performances. The results show that ...... (Is there a maximum threshold of prediction with all these methods? Does an increase in model complexity improve predictability?)

## Results and Discussion

##### Results of modeling in text, tables and figures

##### Comparisons among modeling approaches

#### Interpretation of modeling results in terms of reproducibility, robustness, actionability, interpretibility and susceptibility

#### Consideration of possible weaknesses for each model 

The interactions between the biomarkers may be nonlinear. Obviously, the linear models will not incorporate this because they are linear. Tools like linear models (e.g. metastats, lefse, wilcoxon, etc) are likely worthless.

#### Consideration of possible weaknesses for our approach and chosen dataset

#### Relationship of results to previous literature and broader implications of this work

#### Prospects of future progress

## Conclusions



## Materials and Methods

#### Data collection
  The data used for this analysis are stool bacterial abundances, stool hemoglobin levels and clinical information of the patients recruited by Great Lakes-New England Early Detection Research Network study. These data were obtained from Sze et al [@sze_leveraging_2018]. 
  The stool samples were provided by recruited adult participants who were undergoing scheduled screening or surveillance colonoscopy. Colonoscopies were performed and fecal samples were collected from participants in four locations: Toronto (ON, Canada), Boston (MA, USA), Houston (TX, USA), and Ann Arbor (MI, USA). Patients' colonic disease status was defined by colonoscopy with adequate preparation and tissue histopathology of all resected lesions. Patients with an adenoma greater than 1 cm, more than three adenomas of any size, or an adenoma with villous histology were classified as advanced adenoma. Study had `r paste(sum(meta$dx=="normal"))` patients with normal colonoscopies, `r paste(sum(meta$dx=="adenoma"))` with adenomas and `r paste(sum(meta$dx=="cancer"))` with carcinomas. Of the `r paste(sum(meta$dx=="adenoma"))` adenomas, `r paste(sum(meta$Dx_Bin=="adv Adenoma"))` were identified as advanced adenomas. Stool provided by the patients was used for Fecal Immunological Tests (FIT) which measure human hemoglobin concentrations and for 16S rRNA gene sequencing to measure bacterial population abundances. The bacterial abundance data was generated by Sze et al, by processing 16S rRNA sequences in Mothur (v1.39.3) using the default quality filtering methods, identifying and removing chimeric sequences using VSEARCH and assigning to OTUs at 97% similarity using the OptiClust algorithm [@schloss_introducing_2009; @westcott_opticlust_2017; @rognes_vsearch_2016].

#### Data definitions and pre-processing

  The colonic disease status is re-defined as two encompassing classes; Normal or Screen Relevant Neoplasias (SRNs). Normal class includes patients with non-advanced adenomas or normal colons whereas SRN class includes patients with advanced adenomas or carcinomas. Colonic disease status is the label predicted with each classifier.   The bacterial abundances and FIT results are the features used to predict colonic disease status. Bacterial abundances are discrete data in the form of Operational Taxonomic Unit (OTU) counts. There are 6920 OTUs for each sample. FIT levels are continuous data present for each sample. Because the data are in different scales, Python programming language v`r paste(py$python_version)`, module scikit-learn v`r paste(py$sklearn_module)` is used to transform features by scaling each feature to a [0-1] range (Table 1) [@scikit-learn].
  
#### Learning the Classifier

  To train and validate our model, labeled data is randomly split 80/20 into a training set and testing
set. Then, seven binary class classifiers, L2 logistic regression, L1 and L2 linear suppor vector machines (SVM), radial basis function SVM, decision tree, random forest and XGBoost, are learned. The training set is used for training purposes and validation of hyperparameter selection, and the test set is used for evaluation purposes. Hyperparameters are selected using 5-fold cross-validation with 100-repeats on the training set. Since the colonic disease status are not uniformly represented in the data, 5-fold splits are stratified to maintain the overall label distribution on the training set. Python programming language v`r paste(py$python_version)`, module scikit-learn v`r paste(py$sklearn_module)` functions are used to learn the seven classifiers (Table 1). 

#### Classifier Performance

  The classification performance of learned classifier is evaluated on the labeled held-out testing set. The optimal  classifier with optimal hyperparameters selected in the cross-validation step is used to produce a prediction for the testing set. The performance of this prediction is measured in terms of the sensitivity and specificity, in addition to Area Under the Curve (AUC) metrics. This process of splitting the data, learning a classifier with cross-validation, and testing the classifier is repeated on 100 different splits. In the end cross-validation AUC and testing AUC averaged over the 100 different training/test splits are reported. Hyperparameter budget and performance for each split is also reported. 


\newpage



**Figure 1. Generalization and classification performance of modeling methods ** AUC values of all cross validation and testing performances. The boxplot shows quartiles at the box ends and the statistical median as the horizontal line in the box. The whiskers show the farthest points that are not outliers. Outliers are data points that are not within 3/2 times the interquartile ranges. 

\newpage

## References

<div id="refs"></div>


