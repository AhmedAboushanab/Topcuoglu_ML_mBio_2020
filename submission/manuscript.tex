\documentclass[11pt,]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1.0in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Evaluation of binary classification pipelines and methods for 16S rRNA gene data},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{\textbf{Evaluation of binary classification pipelines and methods for
16S rRNA gene data}}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{}
    \preauthor{}\postauthor{}
    \date{}
    \predate{}\postdate{}
  
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage[table]{xcolor}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}

\usepackage{helvet} % Helvetica font
\renewcommand*\familydefault{\sfdefault} % Use the sans serif version of the font
\usepackage[T1]{fontenc}

\usepackage[none]{hyphenat}

\usepackage{setspace}
\doublespacing
\setlength{\parskip}{1em}

\usepackage{lineno}

\usepackage{pdfpages}
\floatplacement{figure}{H} % Keep the figure up top of the page

\begin{document}
\maketitle

\vspace{35mm}

Running title: Machine learning methods in microbiome studies

\vspace{35mm}

Begüm D. Topçuoğlu\({^1}\), Jenna Wiens\({^2}\), Patrick D.
Schloss\textsuperscript{1\(\dagger\)}

\vspace{40mm}

\(\dagger\) To whom correspondence should be addressed:
\href{mailto:pschloss@umich.edu}{\nolinkurl{pschloss@umich.edu}}

1. Department of Microbiology and Immunology, University of Michigan,
Ann Arbor, MI 48109

2. Department of Computer Science and Engineering, University or
Michigan, Ann Arbor, MI 49109

\newpage

\linenumbers

\subsection{Abstract}\label{abstract}

\newpage

\subsection{Introduction}\label{introduction}

Advances in sequencing technology and decreasing costs of generating 16S
rRNA gene sequences have allowed rapid exploration and taxonomic
characterization of the human associated microbiome. Currently, the
microbiome field is growing at an unprecedented rate and as a result,
there is an ever-increasing demand for reproducible methods for
identifying associations between members of the microbiome and human
health. However, this is an undertaking as human associated microbial
communities are remarkably uneven. It is unlikely that a single species
can explain a disease state comprehensively. It is more likely that
subsets of those communities, in relation to one another and to their
host, account for different disease states. Thus, researchers have
started to explore the utility of machine learning (ML) techniques to
develop predictive models that use microbiota associated biomarkers to
identify healthy and diseased states. However, currently the field's use
of ML lacks clarity and consistency on which methods are used, how these
methods are implemented and if these methods are robust and
reproducible. Moreover, there is a lack of consideration on why a
particular ML model is utilized. There is a wide range of complexity and
interpretibility in models used in microbiome field (1--5); recently
with many that are black boxes which cannot be interpreted by humans
(6--8). ML model choice should reflect the goal of the study; whether it
is to develop the best predictive model or to understand the ecology of
microbiota associated diseases.

One application of machine learning to microbiome data has been to
classify patients as having colorectal tumors based on
microbiota-associated biomarkers. Colorectal cancer (CRC) is one of the
leading causes of death in the US, therefore developing a predictive
model from a stool microbiome assay as a non-invasive screening tool is
a remarkable innovation. However, the efforts to combine ML methods with
relative abundances of bacterial poplations in stool to predict CRC
tumors have been afflicted by flawed ML methods and by the lack of
discussion on modeling choices. In previous studies, \ldots{} There is a
need for implementing consistent and transparent machine learning
practices to generate reproducible and replicable CRC biomarker models.
This study aims to shed light on how much task definition and model
choices can affect the results. Here we performed an empirical analysis
comparing several different modeling pipelines using the same dataset.

As our dataset, we used a previously published CRC study (3) which had
fecal 16S rRNA gene sequences and immunochemical test (FIT) results from
490 patients. We built ML models using 16S abundances and FIT to predict
patients with normal or screen relevant neoplasias (SRN) disease status.
The study had 261 normal and 229 SRN samples. We established modeling
pipelines for L2-regularized logistic regression, L1 and L2 support
vector machines (SVM) with linear and radial basis function kernels, a
decision tree, random forest and XGBoost. These models increase in
complexity while they decrease in interpretability. Our ML pipeline
performed 100 data-splits and utilized held-out test data to evaluate
generalization and predicton performance of each ML model. The mean
AUROC varied from 0.67 (std ± 0.05) to 0.82 (std ± 0.04). Random Forest
and XGBoost had the highest mean AUROC for detecting SRN. In terms of
computational efficiency, L2 Logistic Regression trained the fastest
(0.098 hours, std ± 0.008), while XGBoost took the longest (3.601 hours,
std ± 0.524). We found that mean cross-validation and testing AUROC
could vary by as much as 0.062, which highlights the importance of a
seperate held-out test set for evaluation. Aside from evaluating
generalization and classification performances for each of these models,
this study established standards for modeling pipelines of
microbiome-associated machine learning models.

\subsection{Results and Discussion}\label{results-and-discussion}

\textbf{The prediction and generalization performance of classifiers
during cross-validation and when applied to the held-out test data.}

We evaluated the prediction performance of seven binary classification
models when applied to held-out test data using AUROC as our metric.
Random Forest and XGBoost had the highest mean AUROC for detecting SRN,
0.818 (std ± 0.036) and 0.814 (std ± 0.038) respectively {[}Figure 2{]}.
L1 linear SVM and decision tree had significantly lower AUROC values,
0.748 (std ± 0.043) and 0.741 (std ± 0.038) {[}Figure 2{]}. However,
they had significanly higher performances than L2 linear SVM, RBF SVM
and L2 logistic regression which had mean AUROC values of 0.67 (std ±
0.054), 0.683 (std ± 0.048) and 0.677 (std ± 0.053)
respectively{[}Figure 2{]}. We also evaluated the generalization
performance of each classifier by comparing their mean cross-validation
AUROC and mean testing AUROC. We found a significant difference for
classifiers L2 support vector machines (SVM) with linear and radial
basis function kernels and L2 logistic regression. These differences
were 0.062, 0.047 and 0.061, respectively {[}Figure 2{]} .

\textbf{The prediction performance of classifiers for different
hyperparameter settings.}

\textbf{The interpretation of classifiers.}

\subsection{Conclusions}\label{conclusions}

\subsection{Materials and Methods}\label{materials-and-methods}

\paragraph{Data collection}\label{data-collection}

The data used for this analysis are stool bacterial abundances, stool
hemoglobin levels and clinical information of the patients recruited by
Great Lakes-New England Early Detection Research Network study. These
data were obtained from Sze et al (9). The stool samples were provided
by recruited adult participants who were undergoing scheduled screening
or surveillance colonoscopy. Colonoscopies were performed and fecal
samples were collected from participants in four locations: Toronto (ON,
Canada), Boston (MA, USA), Houston (TX, USA), and Ann Arbor (MI, USA).
Patients' colonic disease status was defined by colonoscopy with
adequate preparation and tissue histopathology of all resected lesions.
Patients with an adenoma greater than 1 cm, more than three adenomas of
any size, or an adenoma with villous histology were classified as
advanced adenoma. Study had 172 patients with normal colonoscopies, 198
with adenomas and 120 with carcinomas. Of the 198 adenomas, 109 were
identified as advanced adenomas. Stool provided by the patients was used
for Fecal Immunological Tests (FIT) which measure human hemoglobin
concentrations and for 16S rRNA gene sequencing to measure bacterial
population abundances. The bacterial abundance data was generated by Sze
et al, by processing 16S rRNA sequences in Mothur (v1.39.3) using the
default quality filtering methods, identifying and removing chimeric
sequences using VSEARCH and assigning to OTUs at 97\% similarity using
the OptiClust algorithm (10--12).

\paragraph{Data definitions and
pre-processing}\label{data-definitions-and-pre-processing}

The colonic disease status is re-defined as two encompassing classes;
Normal or Screen Relevant Neoplasias (SRNs). Normal class includes
patients with non-advanced adenomas or normal colons whereas SRN class
includes patients with advanced adenomas or carcinomas. Colonic disease
status is the label predicted with each classifier. The bacterial
abundances and FIT results are the features used to predict colonic
disease status. Bacterial abundances are discrete data in the form of
Operational Taxonomic Unit (OTU) counts. There are 6920 OTUs for each
sample. FIT levels are continuous data present for each sample. Because
the data are in different scales, Python programming language v, module
scikit-learn v is used to transform features by scaling each feature to
a {[}0-1{]} range (Table 1) (13).

\paragraph{Learning the Classifier}\label{learning-the-classifier}

To train and validate our model, labeled data is randomly split 80/20
into a training set and testing set. Then, seven binary class
classifiers, L2 logistic regression, L1 and L2 linear suppor vector
machines (SVM), radial basis function SVM, decision tree, random forest
and XGBoost, are learned. The training set is used for training purposes
and validation of hyperparameter selection, and the test set is used for
evaluation purposes. Hyperparameters are selected using 5-fold
cross-validation with 100-repeats on the training set. Since the colonic
disease status are not uniformly represented in the data, 5-fold splits
are stratified to maintain the overall label distribution on the
training set.

\paragraph{Classifier Performance}\label{classifier-performance}

The classification performance of learned classifier is evaluated on the
labeled held-out testing set. The optimal classifier with optimal
hyperparameters selected in the cross-validation step is used to produce
a prediction for the testing set. The performance of this prediction is
measured in terms of the sensitivity and specificity, in addition to
Area Under the Curve (AUC) metrics. This process of splitting the data,
learning a classifier with cross-validation, and testing the classifier
is repeated on 100 different splits. In the end cross-validation AUC and
testing AUC averaged over the 100 different training/test splits are
reported. Hyperparameter budget and performance for each split is also
reported.

\newpage

\textbf{Figure 1. Generalization and classification performance of
modeling methods } AUC values of all cross validation and testing
performances. The boxplot shows quartiles at the box ends and the
statistical median as the horizontal line in the box. The whiskers show
the farthest points that are not outliers. Outliers are data points that
are not within 3/2 times the interquartile ranges.

\newpage

\subsection{References}\label{references}

\hypertarget{refs}{}
\hypertarget{ref-zeller_potential_2014}{}
1. \textbf{Zeller G}, \textbf{Tap J}, \textbf{Voigt AY},
\textbf{Sunagawa S}, \textbf{Kultima JR}, \textbf{Costea PI},
\textbf{Amiot A}, \textbf{Böhm J}, \textbf{Brunetti F},
\textbf{Habermann N}, \textbf{Hercog R}, \textbf{Koch M},
\textbf{Luciani A}, \textbf{Mende DR}, \textbf{Schneider MA},
\textbf{Schrotz-King P}, \textbf{Tournigand C}, \textbf{Tran Van Nhieu
J}, \textbf{Yamada T}, \textbf{Zimmermann J}, \textbf{Benes V},
\textbf{Kloor M}, \textbf{Ulrich CM}, \textbf{Knebel Doeberitz M von},
\textbf{Sobhani I}, \textbf{Bork P}. 2014. Potential of fecal microbiota
for early-stage detection of colorectal cancer. Mol Syst Biol
\textbf{10}.
doi:\href{https://doi.org/10.15252/msb.20145645}{10.15252/msb.20145645}.

\hypertarget{ref-zackular_human_2014}{}
2. \textbf{Zackular JP}, \textbf{Rogers MAM}, \textbf{Ruffin MT},
\textbf{Schloss PD}. 2014. The human gut microbiome as a screening tool
for colorectal cancer. Cancer Prev Res \textbf{7}:1112--1121.
doi:\href{https://doi.org/10.1158/1940-6207.CAPR-14-0129}{10.1158/1940-6207.CAPR-14-0129}.

\hypertarget{ref-baxter_dna_2016}{}
3. \textbf{Baxter NT}, \textbf{Koumpouras CC}, \textbf{Rogers MAM},
\textbf{Ruffin MT}, \textbf{Schloss PD}. 2016. DNA from fecal
immunochemical test can replace stool for detection of colonic lesions
using a microbiota-based model. Microbiome \textbf{4}.
doi:\href{https://doi.org/10.1186/s40168-016-0205-y}{10.1186/s40168-016-0205-y}.

\hypertarget{ref-baxter_microbiota-based_2016}{}
4. \textbf{Baxter NT}, \textbf{Ruffin MT}, \textbf{Rogers MAM},
\textbf{Schloss PD}. 2016. Microbiota-based model improves the
sensitivity of fecal immunochemical test for detecting colonic lesions.
Genome Medicine \textbf{8}:37.
doi:\href{https://doi.org/10.1186/s13073-016-0290-3}{10.1186/s13073-016-0290-3}.

\hypertarget{ref-pasolli_machine_2016}{}
5. \textbf{Pasolli E}, \textbf{Truong DT}, \textbf{Malik F},
\textbf{Waldron L}, \textbf{Segata N}. 2016. Machine learning
meta-analysis of large metagenomic datasets: Tools and biological
insights. PLoS Comput Biol \textbf{12}.
doi:\href{https://doi.org/10.1371/journal.pcbi.1004977}{10.1371/journal.pcbi.1004977}.

\hypertarget{ref-galkin_human_2018}{}
6. \textbf{Galkin F}, \textbf{Aliper A}, \textbf{Putin E},
\textbf{Kuznetsov I}, \textbf{Gladyshev VN}, \textbf{Zhavoronkov A}.
2018. Human microbiome aging clocks based on deep learning and tandem of
permutation feature importance and accumulated local effects. bioRxiv.
doi:\href{https://doi.org/10.1101/507780}{10.1101/507780}.

\hypertarget{ref-reiman_using_2017}{}
7. \textbf{Reiman D}, \textbf{Metwally A}, \textbf{Dai Y}. 2017. Using
convolutional neural networks to explore the microbiome, pp. 4269--4272.
\emph{In} 2017 39th annual international conference of the IEEE
engineering in medicine and biology society (EMBC).

\hypertarget{ref-fioravanti_phylogenetic_2017}{}
8. \textbf{Fioravanti D}, \textbf{Giarratano Y}, \textbf{Maggio V},
\textbf{Agostinelli C}, \textbf{Chierici M}, \textbf{Jurman G},
\textbf{Furlanello C}. 2017. Phylogenetic convolutional neural networks
in metagenomics. arXiv:170902268 {[}cs, q-bio{]}.

\hypertarget{ref-sze_leveraging_2018}{}
9. \textbf{Sze MA}, \textbf{Schloss PD}. 2018. Leveraging existing 16S
rRNA gene surveys to identify reproducible biomarkers in individuals
with colorectal tumors. mBio \textbf{9}:e00630--18.
doi:\href{https://doi.org/10.1128/mBio.00630-18}{10.1128/mBio.00630-18}.

\hypertarget{ref-schloss_introducing_2009}{}
10. \textbf{Schloss PD}, \textbf{Westcott SL}, \textbf{Ryabin T},
\textbf{Hall JR}, \textbf{Hartmann M}, \textbf{Hollister EB},
\textbf{Lesniewski RA}, \textbf{Oakley BB}, \textbf{Parks DH},
\textbf{Robinson CJ}, \textbf{Sahl JW}, \textbf{Stres B},
\textbf{Thallinger GG}, \textbf{Van Horn DJ}, \textbf{Weber CF}. 2009.
Introducing mothur: Open-Source, Platform-Independent,
Community-Supported Software for Describing and Comparing Microbial
Communities. ApplEnvironMicrobiol \textbf{75}:7537--7541.

\hypertarget{ref-westcott_opticlust_2017}{}
11. \textbf{Westcott SL}, \textbf{Schloss PD}. 2017. OptiClust, an
Improved Method for Assigning Amplicon-Based Sequence Data to
Operational Taxonomic Units. mSphere \textbf{2}.
doi:\href{https://doi.org/10.1128/mSphereDirect.00073-17}{10.1128/mSphereDirect.00073-17}.

\hypertarget{ref-rognes_vsearch_2016}{}
12. \textbf{Rognes T}, \textbf{Flouri T}, \textbf{Nichols B},
\textbf{Quince C}, \textbf{Mahé F}. 2016. VSEARCH: A versatile open
source tool for metagenomics. PeerJ \textbf{4}:e2584.
doi:\href{https://doi.org/10.7717/peerj.2584}{10.7717/peerj.2584}.

\hypertarget{ref-scikit-learn}{}
13. \textbf{Pedregosa F}, \textbf{Varoquaux G}, \textbf{Gramfort A},
\textbf{Michel V}, \textbf{Thirion B}, \textbf{Grisel O},
\textbf{Blondel M}, \textbf{Prettenhofer P}, \textbf{Weiss R},
\textbf{Dubourg V}, \textbf{Vanderplas J}, \textbf{Passos A},
\textbf{Cournapeau D}, \textbf{Brucher M}, \textbf{Perrot M},
\textbf{Duchesnay E}. 2011. Scikit-learn: Machine learning in Python.
Journal of Machine Learning Research \textbf{12}:2825--2830.


\end{document}
