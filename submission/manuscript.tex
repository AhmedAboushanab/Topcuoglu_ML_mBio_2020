\documentclass[11pt,]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1.0in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Evaluation of machine learning methods for 16S rRNA gene data},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{\textbf{Evaluation of machine learning methods for 16S rRNA gene data}}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{}
    \preauthor{}\postauthor{}
    \date{}
    \predate{}\postdate{}
  
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage[table]{xcolor}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}

\usepackage{helvet} % Helvetica font
\renewcommand*\familydefault{\sfdefault} % Use the sans serif version of the font
\usepackage[T1]{fontenc}

\usepackage[none]{hyphenat}

\usepackage{setspace}
\doublespacing
\setlength{\parskip}{1em}

\usepackage{lineno}

\usepackage{pdfpages}
\floatplacement{figure}{H} % Keep the figure up top of the page

\begin{document}
\maketitle

\vspace{35mm}

Running title: Machine learning methods in microbiome studies

\vspace{35mm}

Begüm D. Topçuoğlu\({^1}\), Jenna Wiens\({^2}\), Patrick D.
Schloss\textsuperscript{1\(\dagger\)}

\vspace{40mm}

\(\dagger\) To whom correspondence should be addressed:
\href{mailto:pschloss@umich.edu}{\nolinkurl{pschloss@umich.edu}}

1. Department of Microbiology and Immunology, University of Michigan,
Ann Arbor, MI 48109

2. Department of Computer Science and Engineering, University or
Michigan, Ann Arbor, MI 49109

\newpage

\linenumbers

\subsection{Abstract}\label{abstract}

\newpage

\subsection{Introduction}\label{introduction}

Advances in sequencing technology and decreasing costs of generating 16S
rRNA gene sequences have allowed rapid exploration of human associated
microbiome and its health implications. Currently, the human microbiome
field is growing at an unprecedented rate and as a result, there is an
increasing demand for methods that identify associations between members
of the microbiome and human health. However, this is difficult as human
associated microbial communities are remarkably complex and uneven. It
is unlikely that a single species can explain a disease. Instead,
subsets of those communities, in relation to one another and to their
host, account for the differences in health outcomes. Machine learning
(ML) methods are effective at recognizing and highlighting patterns in
complex microbial datasets. Therefore, researchers have started to
explore the utility of ML models that use microbiota associated
biomarkers to predict human health and to understand the microbial
ecology of diseases such as liver cirrhosis, colorectal cancer,
inflammatory bowel diseases (IBD), obesity, and type 2 diabetes (1--11).
However, currently the field's use of ML lacks clarity and consistency
on which methods are used and how these methods are implemented. Most
notably, there are misleading practices of using ``leaky'' ML pipelines
where models are tested on training data or reporting the best outcome
of different iterations of cross-validation. Moreover, there is a lack
of discussion on why a particular ML model is utilized. Recently, there
is a trend towards using more complex ML models such as random forest,
extreme gradient boosting and neural networks without a discussion on if
and how much model interpretibility is necessary for the study (11--14).
The lack of transparency on modeling methodology and model selection
negatively impact model reproducibility and reliability. We need to
strive toward better machine learning practices by (1) implementing
consistent and reliable machine learning pipelines; (2) selecting ML
models that reflect the goal of the study as it will inform our
expectations of model accuracy, complexity, interpretibility and
computational efficiency.

To showcase reliable ML pipeline and to shed light on how much ML model
selection can affect modeling results, we performed an empirical
analysis comparing several different ML models using the same dataset
and with a robust ML pipeline. We used a previously published colorectal
cancer (CRC) study (3) which had fecal 16S rRNA gene sequences from 490
patients. We built ML models using fecal 16S rRNA gene sequences to
predict patients with normal colons or patients with colonic tumors
which are called screen relevant neoplasias (SRN). The study had 261
normal and 229 SRN samples. We established modeling pipelines for
L2-regularized logistic regression, L1 and L2 support vector machines
(SVM) with linear and radial basis function kernels, a decision tree,
random forest and XGBoost. Our ML pipeline utilized held-out test data
to evaluate generalization and prediction performance of each ML model.
The mean test AUROC varied from 0.598 (std ± 0.044) to 0.697 (std ±
0.037). Random forest had the highest mean AUROC for detecting SRN.
Despite the simplicity, the L2-regularized logistic regression followed
random forest in performance. In terms of computational efficiency, L2
logistic regression trained the fastest (0.202 hours, std ± 0.019),
while XGBoost took the longest (162.843 hours, std ± 3.986). We found
that mean cross-validation and testing AUROC varied only 0.01, which
highlights the importance of a seperate held-out test set and consistent
preprocessing of the data prior to evaluation. Aside from evaluating
generalization and classification performances for each of these models,
this study established standards for modeling pipelines of
microbiome-associated machine learning models.

\subsection{Results}\label{results}

\textbf{Model selection and construction}

The data has 6920 features (6920 OTUs) and a two-class label that
defines the colonic health of the patients (SRN or normal). All the
cases were independently labeled through colonoscopies. We established
modeling pipelines for a binary prediction task with L2-regularized
logistic regression, L1 and L2 support vector machines (SVM) with linear
and radial basis function kernels, a decision tree, random forest and
XGBoost to emphasize the differences in model accuracy, complexity,
interpretibility and computational efficiency due to model selection. We
randomly split the data into training/validation and test sets 100 times
with a 80/20 proportion {[}Figure 1{]}. Since the colonic health is not
uniformly represented in the data, data-splits are stratified to
maintain the overall label distribution on the training set. For each
data-split, training/validation set consisted of 393 patients (209 SRN),
while the test set was composed of 97 patients (52 SRN). The
training/validation data was used for training purposes and validation
of hyperparameter selection, and the test set was used for evaluation
purposes. Validation of hyperparameter selection was performed using 100
randomizations of five-fold cross-validation on the training/validation
set {[}Figure 1{]}. Similar to the initial data-split, five-fold
cross-validation was also stratified to maintain the overall label
distribution on the training and validation sets. We validated the
cross-validation performances of each hyperparameter setting over the
100 randomizations and selected the best performing hyper-parameter
setting to train the full training/validation dataset {[}Figures S1 and
S2{]}. We then used the held-out test set to evaluate the prediction
performance of each ML model.

\textbf{The prediction and generalization performance of classifiers
during cross-validation and when applied to the held-out test data.}

We evaluated the prediction performance of seven binary classification
models when applied to held-out test data over 100 data-splits using the
area under the receiver operating characteristic curve (AUROC) as the
discriminative performance metric. Random Forest had the highest mean
AUROC for detecting SRN, 0.697 (std ± 0.037) {[}Figure 2{]}. L2 logistic
regression and XGBoost had significantly lower AUROC values, 0.676 (std
± 0.042) and 0.678 (std ± 0.04) {[}Figure 2{]}. Random forest also had
significanly higher performances than L2 linear SVM, RBF SVM and
decision tree which had mean AUROC values of 0.671 (std ± 0.045), 0.663
(std ± 0.044), and 0.598 (std ± 0.044), respectively {[}Figure 2{]}. We
also evaluated the generalization performance of each classifier by
comparing their mean cross-validation AUROC and mean testing AUROC. We
found that mean cross-validation and testing AUROC difference for each
model was below 0.01.

\textbf{The complexity and interpretibility of each classifier.}

We interpreted the feature weights of L1 and L2 SVM with linear kernel
and regression coefficients of L2 logistic regression using the training
data. We calculated the mean weights of all the features fromt the 100
randomizations of five-fold cross-validation {[}Figure 3a{]}. In the
three linear models, OTUs that drove the detection of SRNs belong to
family \emph{Lachnospiraceae} and \emph{Ruminococcaceae} (OTUs x, y, z).
To explain the importance of features in non-linear models, we used
permutation importance on the held-out test data {[}Figure 3b{]}.
Perfectly correlated OTUs were grouped and permuted together to get a
better representation of their effect in the prediction performance of
the model. Non-correlated OTUs were permuted individually.

\textbf{The computational efficiency of each classifier.}

Linear models trained faster than non-linear models. L2 logistic
Rregression and L1 and L2 SVM with linear kernel had training times of
0.2 hours, (std ± 0.02), 0.2 hours, (std ± 0.03), and 0.2 hours, (std ±
0.03), respectively. Whereas, SVM with radial basis function kernel,
decision tree, random forest and xgboost had training times of 9.4
hours, (std ± 0.8), 64.7 hours, (std ± 9.9), 101.3 hours, (std ± 10) and
162.8 hours, (std ± 4), respectively {[}Figure 4{]}.

\subsection{Conclusions}\label{conclusions}

\subsection{Materials and Methods}\label{materials-and-methods}

\paragraph{Data collection and study
population}\label{data-collection-and-study-population}

The data used for this analysis are stool bacterial abundances and
clinical information of the patients recruited by Great Lakes-New
England Early Detection Research Network study. These data were obtained
from Sze et al (15). The stool samples were provided by recruited adult
participants who were undergoing scheduled screening or surveillance
colonoscopy. Colonoscopies were performed and fecal samples were
collected from participants in four locations: Toronto (ON, Canada),
Boston (MA, USA), Houston (TX, USA), and Ann Arbor (MI, USA). Patients'
colonic disease status was defined by colonoscopy with adequate
preparation and tissue histopathology of all resected lesions. Patients
with an adenoma greater than 1 cm, more than three adenomas of any size,
or an adenoma with villous histology were classified as advanced
adenoma. Study had 172 patients with normal colonoscopies, 198 with
adenomas and 120 with carcinomas. Of the 198 adenomas, 109 were
identified as advanced adenomas. Stool provided by the patients was used
for 16S rRNA gene sequencing to measure bacterial population abundances.
The bacterial abundance data was generated by Sze et al, by processing
16S rRNA sequences in Mothur (v1.39.3) using the default quality
filtering methods, identifying and removing chimeric sequences using
VSEARCH and assigning to OTUs at 97\% similarity using the OptiClust
algorithm (16--18).

\paragraph{Data definitions and
pre-processing}\label{data-definitions-and-pre-processing}

The colonic health of the patient was defined as two encompassing
classes; Normal or Screen Relevant Neoplasias (SRNs). Normal class
includes patients with non-advanced adenomas or normal colons whereas
SRN class includes patients with advanced adenomas or carcinomas. The
bacterial abundances are the features used to predict colonic health of
the patients. Bacterial abundances are discrete data in the form of
Operational Taxonomic Unit (OTU) counts. OTU counts were set to the size
of our smallest sample and were subsampled at the same distances. They
were then transformd by scaling to a {[}0-1{]} range.

\paragraph{Model training and
evaluation}\label{model-training-and-evaluation}

For L2-regularized logistic regression, L1 and L2 support vector
machines (SVM) with linear and radial basis function kernels we tuned
the \textbf{cost} hyperparameter which determines the regularization
strength where smaller values specify stronger regularization. For SVM
with radial basis function kernel we also tuned \textbf{sigma}
hyperparameter which determines the reach of a single training instance
where for a high value of sigma, the SVM decision boundary will be
dependent on the points that are closest to the decision boundary. For
the decision tree model, we tuned the \textbf{depth of the tree} where
deeper the tree, the more splits it has. For random forest, we tuned the
\textbf{number of features} to consider when looking for the best tree
split. For xgboost, we tuned for \textbf{learning rate} and the
\textbf{fraction of samples} to be used for fitting the individual base
learners. Models were trained using the machine learning wrapper caret
package (v.6.0.81) in R (v.3.5.0).

\textbf{Statistical analysis workflow.} Data summaries, statistical
analysis, and data visualizations were performed using R (v.3.5.0) with
the tidyverse package (v.1.2.1). We compared the AUROC values of the
seven ML models by Wilcoxon rank sum tests to determine the best
discriminative performance.

\textbf{Code availability.} The code for all sequence curation and
analysis steps including an Rmarkdown version of this manuscript is
available at
\url{https://github.com/SchlossLab/Topcuoglu_ML_XXXX_2019/}.

\newpage

\textbf{Figure 1. Generalization and classification performance of
modeling methods } AUC values of all cross validation and testing
performances. The boxplot shows quartiles at the box ends and the
statistical median as the horizontal line in the box. The whiskers show
the farthest points that are not outliers. Outliers are data points that
are not within 3/2 times the interquartile ranges.

\newpage

\subsection{References}\label{references}

\hypertarget{refs}{}
\hypertarget{ref-zeller_potential_2014}{}
1. \textbf{Zeller G}, \textbf{Tap J}, \textbf{Voigt AY},
\textbf{Sunagawa S}, \textbf{Kultima JR}, \textbf{Costea PI},
\textbf{Amiot A}, \textbf{Böhm J}, \textbf{Brunetti F},
\textbf{Habermann N}, \textbf{Hercog R}, \textbf{Koch M},
\textbf{Luciani A}, \textbf{Mende DR}, \textbf{Schneider MA},
\textbf{Schrotz-King P}, \textbf{Tournigand C}, \textbf{Tran Van Nhieu
J}, \textbf{Yamada T}, \textbf{Zimmermann J}, \textbf{Benes V},
\textbf{Kloor M}, \textbf{Ulrich CM}, \textbf{Knebel Doeberitz M von},
\textbf{Sobhani I}, \textbf{Bork P}. 2014. Potential of fecal microbiota
for early-stage detection of colorectal cancer. Mol Syst Biol
\textbf{10}.
doi:\href{https://doi.org/10.15252/msb.20145645}{10.15252/msb.20145645}.

\hypertarget{ref-zackular_human_2014}{}
2. \textbf{Zackular JP}, \textbf{Rogers MAM}, \textbf{Ruffin MT},
\textbf{Schloss PD}. 2014. The human gut microbiome as a screening tool
for colorectal cancer. Cancer Prev Res \textbf{7}:1112--1121.
doi:\href{https://doi.org/10.1158/1940-6207.CAPR-14-0129}{10.1158/1940-6207.CAPR-14-0129}.

\hypertarget{ref-baxter_dna_2016}{}
3. \textbf{Baxter NT}, \textbf{Koumpouras CC}, \textbf{Rogers MAM},
\textbf{Ruffin MT}, \textbf{Schloss PD}. 2016. DNA from fecal
immunochemical test can replace stool for detection of colonic lesions
using a microbiota-based model. Microbiome \textbf{4}.
doi:\href{https://doi.org/10.1186/s40168-016-0205-y}{10.1186/s40168-016-0205-y}.

\hypertarget{ref-baxter_microbiota-based_2016}{}
4. \textbf{Baxter NT}, \textbf{Ruffin MT}, \textbf{Rogers MAM},
\textbf{Schloss PD}. 2016. Microbiota-based model improves the
sensitivity of fecal immunochemical test for detecting colonic lesions.
Genome Medicine \textbf{8}:37.
doi:\href{https://doi.org/10.1186/s13073-016-0290-3}{10.1186/s13073-016-0290-3}.

\hypertarget{ref-hale_shifts_2017}{}
5. \textbf{Hale VL}, \textbf{Chen J}, \textbf{Johnson S},
\textbf{Harrington SC}, \textbf{Yab TC}, \textbf{Smyrk TC},
\textbf{Nelson H}, \textbf{Boardman LA}, \textbf{Druliner BR},
\textbf{Levin TR}, \textbf{Rex DK}, \textbf{Ahnen DJ}, \textbf{Lance P},
\textbf{Ahlquist DA}, \textbf{Chia N}. 2017. Shifts in the fecal
microbiota associated with adenomatous polyps. Cancer Epidemiol
Biomarkers Prev \textbf{26}:85--94.
doi:\href{https://doi.org/10.1158/1055-9965.EPI-16-0337}{10.1158/1055-9965.EPI-16-0337}.

\hypertarget{ref-pasolli_machine_2016}{}
6. \textbf{Pasolli E}, \textbf{Truong DT}, \textbf{Malik F},
\textbf{Waldron L}, \textbf{Segata N}. 2016. Machine learning
meta-analysis of large metagenomic datasets: Tools and biological
insights. PLoS Comput Biol \textbf{12}.
doi:\href{https://doi.org/10.1371/journal.pcbi.1004977}{10.1371/journal.pcbi.1004977}.

\hypertarget{ref-sze_looking_2016}{}
7. \textbf{Sze MA}, \textbf{Schloss PD}. 2016. Looking for a signal in
the noise: Revisiting obesity and the microbiome. mBio \textbf{7}.
doi:\href{https://doi.org/10.1128/mBio.01018-16}{10.1128/mBio.01018-16}.

\hypertarget{ref-walters_meta-analyses_2014}{}
8. \textbf{Walters WA}, \textbf{Xu Z}, \textbf{Knight R}. 2014.
Meta-analyses of human gut microbes associated with obesity and IBD.
FEBS Lett \textbf{588}:4223--4233.
doi:\href{https://doi.org/10.1016/j.febslet.2014.09.039}{10.1016/j.febslet.2014.09.039}.

\hypertarget{ref-vazquez-baeza_guiding_2018}{}
9. \textbf{Vázquez-Baeza Y}, \textbf{Gonzalez A}, \textbf{Xu ZZ},
\textbf{Washburne A}, \textbf{Herfarth HH}, \textbf{Sartor RB},
\textbf{Knight R}. 2018. Guiding longitudinal sampling in IBD cohorts.
Gut \textbf{67}:1743--1745.
doi:\href{https://doi.org/10.1136/gutjnl-2017-315352}{10.1136/gutjnl-2017-315352}.

\hypertarget{ref-qin_alterations_2014}{}
10. \textbf{Qin N}, \textbf{Yang F}, \textbf{Li A}, \textbf{Prifti E},
\textbf{Chen Y}, \textbf{Shao L}, \textbf{Guo J}, \textbf{Le Chatelier
E}, \textbf{Yao J}, \textbf{Wu L}, \textbf{Zhou J}, \textbf{Ni S},
\textbf{Liu L}, \textbf{Pons N}, \textbf{Batto JM}, \textbf{Kennedy SP},
\textbf{Leonard P}, \textbf{Yuan C}, \textbf{Ding W}, \textbf{Chen Y},
\textbf{Hu X}, \textbf{Zheng B}, \textbf{Qian G}, \textbf{Xu W},
\textbf{Ehrlich SD}, \textbf{Zheng S}, \textbf{Li L}. 2014. Alterations
of the human gut microbiome in liver cirrhosis. Nature
\textbf{513}:59--64.
doi:\href{https://doi.org/10.1038/nature13568}{10.1038/nature13568}.

\hypertarget{ref-geman_deep_2018}{}
11. \textbf{Geman O}, \textbf{Chiuchisan I}, \textbf{Covasa M},
\textbf{Doloc C}, \textbf{Milici M-R}, \textbf{Milici L-D}. 2018. Deep
learning tools for human microbiome big data, pp. 265--275. \emph{In}
Balas, VE, Jain, LC, Balas, MM (eds.), Soft computing applications.
Springer International Publishing.

\hypertarget{ref-galkin_human_2018}{}
12. \textbf{Galkin F}, \textbf{Aliper A}, \textbf{Putin E},
\textbf{Kuznetsov I}, \textbf{Gladyshev VN}, \textbf{Zhavoronkov A}.
2018. Human microbiome aging clocks based on deep learning and tandem of
permutation feature importance and accumulated local effects. bioRxiv.
doi:\href{https://doi.org/10.1101/507780}{10.1101/507780}.

\hypertarget{ref-reiman_using_2017}{}
13. \textbf{Reiman D}, \textbf{Metwally A}, \textbf{Dai Y}. 2017. Using
convolutional neural networks to explore the microbiome, pp. 4269--4272.
\emph{In} 2017 39th annual international conference of the IEEE
engineering in medicine and biology society (EMBC).

\hypertarget{ref-fioravanti_phylogenetic_2017}{}
14. \textbf{Fioravanti D}, \textbf{Giarratano Y}, \textbf{Maggio V},
\textbf{Agostinelli C}, \textbf{Chierici M}, \textbf{Jurman G},
\textbf{Furlanello C}. 2017. Phylogenetic convolutional neural networks
in metagenomics. arXiv:170902268 {[}cs, q-bio{]}.

\hypertarget{ref-sze_leveraging_2018}{}
15. \textbf{Sze MA}, \textbf{Schloss PD}. 2018. Leveraging existing 16S
rRNA gene surveys to identify reproducible biomarkers in individuals
with colorectal tumors. mBio \textbf{9}:e00630--18.
doi:\href{https://doi.org/10.1128/mBio.00630-18}{10.1128/mBio.00630-18}.

\hypertarget{ref-schloss_introducing_2009}{}
16. \textbf{Schloss PD}, \textbf{Westcott SL}, \textbf{Ryabin T},
\textbf{Hall JR}, \textbf{Hartmann M}, \textbf{Hollister EB},
\textbf{Lesniewski RA}, \textbf{Oakley BB}, \textbf{Parks DH},
\textbf{Robinson CJ}, \textbf{Sahl JW}, \textbf{Stres B},
\textbf{Thallinger GG}, \textbf{Van Horn DJ}, \textbf{Weber CF}. 2009.
Introducing mothur: Open-Source, Platform-Independent,
Community-Supported Software for Describing and Comparing Microbial
Communities. ApplEnvironMicrobiol \textbf{75}:7537--7541.

\hypertarget{ref-westcott_opticlust_2017}{}
17. \textbf{Westcott SL}, \textbf{Schloss PD}. 2017. OptiClust, an
Improved Method for Assigning Amplicon-Based Sequence Data to
Operational Taxonomic Units. mSphere \textbf{2}.
doi:\href{https://doi.org/10.1128/mSphereDirect.00073-17}{10.1128/mSphereDirect.00073-17}.

\hypertarget{ref-rognes_vsearch_2016}{}
18. \textbf{Rognes T}, \textbf{Flouri T}, \textbf{Nichols B},
\textbf{Quince C}, \textbf{Mahé F}. 2016. VSEARCH: A versatile open
source tool for metagenomics. PeerJ \textbf{4}:e2584.
doi:\href{https://doi.org/10.7717/peerj.2584}{10.7717/peerj.2584}.


\end{document}
